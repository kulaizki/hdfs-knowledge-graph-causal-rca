{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDFS Knowledge Graph Visualization\n",
    "\n",
    "This notebook demonstrates the use of the HDFS Knowledge Graph module to build, analyze, and visualize knowledge graphs from HDFS log data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m sys.path.append(\u001b[33m'\u001b[39m\u001b[33m../src\u001b[39m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# Add src directory to path\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnx\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')  # Add src directory to path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Import functions from the graph module\n",
    "from graph import (\n",
    "    create_hdfs_knowledge_graph, \n",
    "    find_common_patterns,\n",
    "    analyze_graph,\n",
    "    visualize_graph,\n",
    "    save_knowledge_graph,\n",
    "    load_knowledge_graph,\n",
    "    get_trace_subgraph\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating a Knowledge Graph\n",
    "\n",
    "First, let's create a knowledge graph from the HDFS log data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the data directory - adjust path as needed\n",
    "data_dir = \"../data/processed\"\n",
    "\n",
    "# Create the knowledge graph\n",
    "kg = create_hdfs_knowledge_graph(data_dir)\n",
    "\n",
    "# Alternatively, if you've already saved a graph, you can load it:\n",
    "# kg = load_knowledge_graph(\"../reports/hdfs_knowledge_graph.pkl\", data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyzing Graph Statistics\n",
    "\n",
    "Let's examine the statistics of our knowledge graph to better understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get graph statistics\n",
    "stats = analyze_graph(kg)\n",
    "\n",
    "# Display basic graph properties\n",
    "print(f\"Total nodes: {stats['num_nodes']}\")\n",
    "print(f\"Total edges: {stats['num_edges']}\")\n",
    "print(f\"Number of connected components: {stats['num_components']}\")\n",
    "\n",
    "# Display node type distribution\n",
    "print(\"\\nNode types:\")\n",
    "for node_type, count in stats['node_types'].items():\n",
    "    print(f\"  {node_type}: {count}\")\n",
    "\n",
    "# Display edge relation distribution\n",
    "print(\"\\nEdge relations:\")\n",
    "for relation, count in stats['edge_relations'].items():\n",
    "    print(f\"  {relation}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Identifying Common Patterns\n",
    "\n",
    "Let's find common event sequences in the HDFS logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify common event patterns\n",
    "common_sequences = find_common_patterns(kg)\n",
    "\n",
    "# Display the top sequences in a more readable format\n",
    "print(\"\\nTop common event sequences:\")\n",
    "for i, (seq, count) in enumerate(common_sequences[:5], 1):\n",
    "    print(f\"\\nSequence {i} (occurs {count} times):\")\n",
    "    for j, event_id in enumerate(seq, 1):\n",
    "        print(f\"  Step {j}: Event {event_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizing the Graph\n",
    "\n",
    "Now, let's visualize the knowledge graph to better understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph with a limited number of nodes for clarity\n",
    "# This displays the graph in the notebook\n",
    "visualize_graph(kg, max_nodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a larger visualization to a file\n",
    "os.makedirs(\"../reports\", exist_ok=True)\n",
    "output_path = \"../reports/hdfs_knowledge_graph_large.png\"\n",
    "visualize_graph(kg, max_nodes=300, output_path=output_path)\n",
    "\n",
    "# Display the saved image\n",
    "from IPython.display import Image\n",
    "Image(filename=output_path, width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Examining a Specific Trace\n",
    "\n",
    "Let's extract and visualize a specific trace for deeper analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of block IDs in the knowledge graph\n",
    "block_ids = [d['block_id'] for _, d in kg.graph.nodes(data=True) \n",
    "             if d.get('type') == 'Trace' and 'block_id' in d]\n",
    "\n",
    "# Display some sample block IDs\n",
    "print(f\"Found {len(block_ids)} block IDs in the graph.\")\n",
    "print(\"Sample block IDs:\")\n",
    "for block_id in block_ids[:5]:\n",
    "    print(f\"  {block_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a block ID to examine (using the first one from our sample)\n",
    "if block_ids:\n",
    "    selected_block_id = block_ids[0]\n",
    "    \n",
    "    # Get the subgraph for this trace\n",
    "    trace_subgraph = get_trace_subgraph(kg, selected_block_id)\n",
    "    \n",
    "    if trace_subgraph:\n",
    "        print(f\"Extracted subgraph for block {selected_block_id} with {trace_subgraph.number_of_nodes()} nodes\")\n",
    "        \n",
    "        # Visualize the trace subgraph\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        pos = nx.spring_layout(trace_subgraph, seed=42)\n",
    "        \n",
    "        # Create node colors based on node type\n",
    "        node_colors = []\n",
    "        for node in trace_subgraph.nodes():\n",
    "            node_type = trace_subgraph.nodes[node].get('type', '')\n",
    "            if node_type == 'Component':\n",
    "                node_colors.append('skyblue')\n",
    "            elif node_type == 'EventType':\n",
    "                node_colors.append('lightgreen')\n",
    "            elif node_type == 'Event':\n",
    "                node_colors.append('orange')\n",
    "            elif node_type == 'Trace':\n",
    "                node_colors.append('green')\n",
    "            else:\n",
    "                node_colors.append('gray')\n",
    "        \n",
    "        nx.draw(trace_subgraph, pos, with_labels=True, node_color=node_colors,\n",
    "                font_size=8, node_size=500, font_weight='bold',\n",
    "                edge_color='gray', width=0.5, alpha=0.8)\n",
    "        \n",
    "        plt.title(f\"Trace Subgraph for Block {selected_block_id}\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No subgraph found for block {selected_block_id}\")\n",
    "else:\n",
    "    print(\"No block IDs found in the graph.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving the Knowledge Graph\n",
    "\n",
    "Let's save our knowledge graph for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the reports directory if it doesn't exist\n",
    "os.makedirs(\"../reports\", exist_ok=True)\n",
    "\n",
    "# Save the graph\n",
    "save_knowledge_graph(kg, \"../reports/hdfs_knowledge_graph.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Analysis: Event Type Distribution\n",
    "\n",
    "Let's analyze the distribution of event types in our logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract event type nodes\n",
    "event_type_nodes = [n for n, d in kg.graph.nodes(data=True) if d.get('type') == 'EventType']\n",
    "\n",
    "# Count event instances per event type\n",
    "event_type_counts = {}\n",
    "for node in event_type_nodes:\n",
    "    event_id = kg.graph.nodes[node].get('event_id')\n",
    "    template = kg.graph.nodes[node].get('template', 'Unknown')\n",
    "    # Count instances pointing to this event type\n",
    "    instances = sum(1 for _, target, data in kg.graph.edges(data=True) \n",
    "                    if target == node and data.get('relation') == 'instance_of')\n",
    "    event_type_counts[event_id] = (instances, template)\n",
    "\n",
    "# Sort by frequency\n",
    "sorted_event_types = sorted(event_type_counts.items(), key=lambda x: x[1][0], reverse=True)\n",
    "\n",
    "# Display the most common event types\n",
    "print(\"Most common event types:\")\n",
    "for event_id, (count, template) in sorted_event_types[:10]:\n",
    "    print(f\"EventID: {event_id}, Occurrences: {count}\")\n",
    "    print(f\"Template: {template}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize event type distribution\n",
    "top_events = sorted_event_types[:15]  # Top 15 event types\n",
    "event_ids = [event_id for event_id, _ in top_events]\n",
    "counts = [count for _, (count, _) in top_events]\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "bars = plt.bar(event_ids, counts, color='skyblue')\n",
    "plt.xlabel('Event ID')\n",
    "plt.ylabel('Number of Occurrences')\n",
    "plt.title('Distribution of Top 15 Event Types')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add count labels on top of bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "            f'{height:.0f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Component Analysis\n",
    "\n",
    "Let's analyze the distribution and relationship between components in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract component nodes\n",
    "component_nodes = [n for n, d in kg.graph.nodes(data=True) if d.get('type') == 'Component']\n",
    "component_names = [kg.graph.nodes[n].get('name', 'Unknown') for n in component_nodes]\n",
    "\n",
    "print(f\"Found {len(component_nodes)} distinct components:\")\n",
    "for name in component_names:\n",
    "    print(f\"  - {name}\")\n",
    "\n",
    "# Count events by component\n",
    "component_event_counts = {}\n",
    "for component_node in component_nodes:\n",
    "    component_name = kg.graph.nodes[component_node].get('name', 'Unknown')\n",
    "    # Count events connected to this component\n",
    "    events = sum(1 for source, target, data in kg.graph.edges(data=True) \n",
    "                if target == component_node and data.get('relation') == 'executed_by')\n",
    "    component_event_counts[component_name] = events\n",
    "\n",
    "# Display event counts by component\n",
    "print(\"\\nEvent counts by component:\")\n",
    "for component, count in sorted(component_event_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {component}: {count} events\")\n",
    "\n",
    "# Visualize component distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.pie([count for count in component_event_counts.values()], \n",
    "        labels=[f\"{comp} ({count})\" for comp, count in component_event_counts.items()],\n",
    "        autopct='%1.1f%%',\n",
    "        startangle=90,\n",
    "        shadow=True)\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "plt.title('Distribution of Events by Component')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Analyzing Temporal Patterns\n",
    "\n",
    "Let's look at the temporal distribution of events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract event nodes with timestamps\n",
    "event_nodes = []\n",
    "for node, data in kg.graph.nodes(data=True):\n",
    "    if data.get('type') == 'Event' and 'timestamp' in data:\n",
    "        event_nodes.append((node, data['timestamp']))\n",
    "\n",
    "# Convert timestamps to pandas datetime\n",
    "if event_nodes:\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Attempt to parse timestamps\n",
    "    timestamps = []\n",
    "    for _, ts_str in event_nodes:\n",
    "        try:\n",
    "            ts = pd.to_datetime(ts_str)\n",
    "            timestamps.append(ts)\n",
    "        except:\n",
    "            # Skip unparseable timestamps\n",
    "            continue\n",
    "    \n",
    "    if timestamps:\n",
    "        # Create a time series of event counts\n",
    "        ts_series = pd.Series(timestamps).value_counts().sort_index()\n",
    "        \n",
    "        # Resample to minute frequency to see patterns\n",
    "        minute_counts = ts_series.resample('1min').sum().fillna(0)\n",
    "        \n",
    "        # Plot time series\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        minute_counts.plot()\n",
    "        plt.title('Events Over Time (1-minute intervals)')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Number of Events')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "        # Show more detailed statistics\n",
    "        print(f\"Temporal analysis of {len(timestamps)} events:\")\n",
    "        print(f\"First event: {timestamps[0]}\")\n",
    "        print(f\"Last event: {timestamps[-1]}\")\n",
    "        print(f\"Total time span: {timestamps[-1] - timestamps[0]}\")\n",
    "        print(f\"Average events per minute: {len(timestamps) / ((timestamps[-1] - timestamps[0]).total_seconds() / 60):.2f}\")\n",
    "    else:\n",
    "        print(\"No valid timestamps found in event data.\")\n",
    "else:\n",
    "    print(\"No event nodes with timestamps found in the graph.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion and Next Steps\n",
    "\n",
    "In this notebook, we have:\n",
    "1. Built a knowledge graph from HDFS log data\n",
    "2. Analyzed the graph structure and statistics\n",
    "3. Identified common event patterns\n",
    "4. Visualized the graph and specific traces\n",
    "5. Performed more detailed analyses of event types, components, and temporal patterns\n",
    "\n",
    "Potential next steps could include:\n",
    "- Anomaly detection based on unusual event patterns\n",
    "- Predictive modeling for system failures\n",
    "- Root cause analysis using graph traversal algorithms\n",
    "- Integration with real-time monitoring systems"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
